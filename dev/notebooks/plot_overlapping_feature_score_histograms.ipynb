{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "import logging\n",
    "import csv\n",
    "\n",
    "def read_inferred_network(inferred_network_file: str) -> dd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads the melted sparse inferred-network parquet (source_id, peak_id, target_id, score_type, score_value)\n",
    "    and pivots it back to wide form *including* peak_id in the index.\n",
    "    \"\"\"\n",
    "    melted_ddf = dd.read_parquet(inferred_network_file, engine=\"pyarrow\")\n",
    "\n",
    "    # Standardize IDs\n",
    "    melted_ddf[\"source_id\"] = melted_ddf[\"source_id\"].str.upper()\n",
    "    melted_ddf[\"target_id\"] = melted_ddf[\"target_id\"].str.upper()\n",
    "    # peak_id probably doesn't need uppercasing but you could if you like:\n",
    "    # melted_ddf[\"peak_id\"]   = melted_ddf[\"peak_id\"].str.upper()\n",
    "\n",
    "    # 1) group on THREE id-columns + score_type\n",
    "    grouped = (\n",
    "        melted_ddf\n",
    "        .groupby([\"source_id\", \"peak_id\", \"target_id\", \"score_type\"])\n",
    "        [\"score_value\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # 2) pivot in pandas (safe since it's already aggregated)\n",
    "    pdf = grouped.compute()\n",
    "    wide = pdf.pivot_table(\n",
    "        index=[\"source_id\", \"peak_id\", \"target_id\"],\n",
    "        columns=\"score_type\",\n",
    "        values=\"score_value\",\n",
    "        aggfunc=\"first\"       # now that each is unique per id-triple\n",
    "    ).reset_index()\n",
    "\n",
    "    # 3) back to Dask if you want\n",
    "    return dd.from_pandas(wide, npartitions=1)\n",
    "\n",
    "def read_ground_truth(ground_truth_file):\n",
    "    logging.info(\"Reading in the ground truth\")\n",
    "    ground_truth = pd.read_csv(ground_truth_file, sep='\\t', quoting=csv.QUOTE_NONE, on_bad_lines='skip', header=0)\n",
    "    ground_truth = ground_truth.rename(columns={\"Source\": \"source_id\", \"Target\": \"target_id\"})\n",
    "    return ground_truth\n",
    "\n",
    "def label_edges_with_ground_truth(inferred_network_dd, ground_truth_df):\n",
    "    logging.info(\"Creating ground truth set\")\n",
    "    ground_truth_pairs = set(zip(\n",
    "        ground_truth_df[\"source_id\"].str.upper(),\n",
    "        ground_truth_df[\"target_id\"].str.upper()\n",
    "    ))\n",
    "\n",
    "    logging.info(\"Adding labels to inferred network\")\n",
    "\n",
    "    def label_partition(df):\n",
    "        df = df.copy()  # <-- avoids SettingWithCopyWarning\n",
    "        tf_tg_tuples = list(zip(df[\"source_id\"], df[\"target_id\"]))\n",
    "        df.loc[:, \"label\"] = [1 if pair in ground_truth_pairs else 0 for pair in tf_tg_tuples]\n",
    "        return df\n",
    "\n",
    "    inferred_network_dd = inferred_network_dd.map_partitions(\n",
    "        label_partition,\n",
    "        meta=inferred_network_dd._meta.assign(label=np.int64(0))\n",
    "    )\n",
    "\n",
    "    return inferred_network_dd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_score_histograms(\n",
    "    features,\n",
    "    inferred_network1,\n",
    "    inferred_network2,\n",
    "    label1_name,\n",
    "    label2_name\n",
    "):\n",
    "    print(\"\\tPlotting feature score histograms\")\n",
    "    \n",
    "    # materialize only needed columns\n",
    "    if isinstance(inferred_network1, dd.DataFrame):\n",
    "        print(\"\\tConverting feature columns from Dask to pandas for plotting\")\n",
    "        inferred_network1 = inferred_network1[features].compute()\n",
    "    if isinstance(inferred_network2, dd.DataFrame):\n",
    "        inferred_network2 = inferred_network2[features].compute()\n",
    "\n",
    "    ncols = 4\n",
    "    nrows = math.ceil(len(features) / ncols)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(5 * ncols, 4 * nrows), squeeze=False)\n",
    "\n",
    "    # flatten axes for easy indexing\n",
    "    axes_flat = axes.flat\n",
    "\n",
    "    for ax, feature in zip(axes_flat, features):\n",
    "        # draw into this axis explicitly:\n",
    "        sns.histplot(\n",
    "            inferred_network1[feature].dropna(),\n",
    "            bins=50, alpha=0.7,\n",
    "            color='#1682b1', edgecolor=\"#032b5f\",\n",
    "            stat='proportion',\n",
    "            label=label1_name,\n",
    "            ax=ax\n",
    "        )\n",
    "        sns.histplot(\n",
    "            inferred_network2[feature].dropna(),\n",
    "            bins=50, alpha=0.7,\n",
    "            color=\"#cb5f17\", edgecolor=\"#b13301\",\n",
    "            stat='proportion',\n",
    "            label=label2_name,\n",
    "            ax=ax\n",
    "        )\n",
    "\n",
    "        # set titles/labels on the same ax\n",
    "        ax.set_title(feature, fontsize=14)\n",
    "        ax.set_xlabel(feature, fontsize=14)\n",
    "        ax.set_ylabel(\"Proportion\", fontsize=14)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.tick_params(axis='both', labelsize=12)\n",
    "\n",
    "    # turn off any leftover empty subplots\n",
    "    for ax in axes_flat[len(features):]:\n",
    "        ax.set_visible(False)\n",
    "\n",
    "    # figure-level legend\n",
    "    handles, labels = axes[0,0].get_legend_handles_labels()\n",
    "    fig.legend(\n",
    "        handles, labels,\n",
    "        loc=\"lower center\",\n",
    "        ncol=2,\n",
    "        fontsize=14,\n",
    "        bbox_to_anchor=(0.5, -0.02)\n",
    "    )\n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_file: str = \"/gpfs/Labs/Uzun/DATA/PROJECTS/2024.SC_MO_TRN_DB.MIRA/REPOSITORY/CURRENT/REFERENCE_NETWORKS/RN111_ChIPSeq_BEELINE_Mouse_ESC.tsv\"\n",
    "\n",
    "inferred_network1_file: str = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/output/combined_inferred_dfs/mESC_combined_inferred_score_df.parquet\"\n",
    "# inferred_network1_file: str = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/output/mESC/filtered_L2_E7.5_rep2/inferred_grns/inferred_score_df.parquet\"\n",
    "\n",
    "inferred_network2_file: str = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/output/DS011_mESC/DS011_mESC_sample1/inferred_grns/inferred_score_df.parquet\"\n",
    "\n",
    "inferred_network1_dd = read_inferred_network(inferred_network1_file)\n",
    "inferred_network2_dd = read_inferred_network(inferred_network2_file)\n",
    "\n",
    "print(inferred_network1_dd.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    'mean_TF_expression',\n",
    "    'mean_peak_accessibility',\n",
    "    'mean_TG_expression',\n",
    "    'cicero_score',\n",
    "    # 'correlation',\n",
    "    # 'TSS_dist_score', \n",
    "    # 'homer_binding_score', \n",
    "    'sliding_window_score', \n",
    "    'string_combined_score', \n",
    "    'string_experimental_score', \n",
    "    'string_textmining_score'\n",
    "    ]\n",
    "\n",
    "plot_feature_score_histograms(feature_names, inferred_network1_dd, inferred_network2_dd, \"Combined mESC\", \"DS011 mESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['TSS_dist_score', 'correlation', 'cicero_score']\n",
    "\n",
    "plot_feature_score_histograms(feature_names, inferred_network1_dd, inferred_network2_dd, \"filtered_L2_E7.5_rep2\", \"DS011 mESC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
