{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to my_env (Python 3.9.18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing ChIP-seq TF to genomic location with sliding window method predictions\n",
    "\n",
    "This notebook uses ChIP-seq peaks from ChIP-Atlas as the input for calculating sliding window TF to peak binding scores. As the sliding window score attempts to match TFs to peaks, we can check the accuracy of our methods by comparing which TFs are predicted to bind the ChIP-seq peaks against the TFs that actually bound those locations.\n",
    "\n",
    "The first thing that we need to do is to download and clean the ChIP-seq dataset to only contain the TF `gene_id`s and the formatted `peak_id`s.\n",
    "\n",
    "The ChIP-Atlas dataset we are using can be downloaded from:\n",
    "\n",
    "`wget https://chip-atlas.dbcls.jp/data/mm10/assembled/Oth.Emb.05.AllAg.AllCell.bed`\n",
    "\n",
    "This file corresponds to the following settings in the Peak Browser:\n",
    "- Species -> M. musculus (mm10)\n",
    "- Track type class -> ChIP: TFs and others\n",
    "- Cell type class -> Embryo\n",
    "- Threshold for Significance -> 50\n",
    "- Track type -> All\n",
    "- Cell type -> all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!hostnamectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pybedtools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "base_dir = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/\"\n",
    "ground_truth_dir = os.path.join(base_dir, \"ground_truth_files\")\n",
    "output_dir = os.path.join(base_dir, \"output/chipseq_sliding_window\")\n",
    "tmp_dir = os.path.join(output_dir, \"tmp\")\n",
    "\n",
    "os.makedirs(ground_truth_dir, exist_ok=True)\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(tmp_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_gene_name(name):\n",
    "    return name.split(\"Name=\")[1].split(\"%\")[0]\n",
    "\n",
    "def format_peak_id(chrom, start, end):\n",
    "    start = str(int(start))\n",
    "    end = str(int(end))\n",
    "    return \"%s:%s-%s\" % (chrom, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_bed_file = os.path.join(ground_truth_dir, \"Oth.Emb.05.AllAg.AllCell.bed\")\n",
    "chip_bed = pybedtools.BedTool(chip_bed_file)\n",
    "chip_bed_df = chip_bed.to_dataframe()\n",
    "chip_bed_nohead = chip_bed_df.iloc[1:, :].dropna()\n",
    "\n",
    "chip_bed_nohead[\"gene_id\"] = chip_bed_nohead[\"name\"].apply(extract_gene_name)\n",
    "chip_bed_cleaned = chip_bed_nohead[[\"chrom\", \"start\", \"end\", \"gene_id\"]]\n",
    "\n",
    "# Set the peak_id as the formatted peak location\n",
    "chip_bed_cleaned[\"peak_id\"] = chip_bed_cleaned.apply(lambda x: format_peak_id(x.chrom, x.start, x.end), axis=1)\n",
    "\n",
    "chip_tf_to_peak = chip_bed_cleaned[[\"gene_id\", \"peak_id\"]]\n",
    "chip_tf_to_peak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the ChIP-Atlas peaks in the format that we want, we can save it to the ground truth directory for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_tf_to_peak.to_csv(os.path.join(ground_truth_dir, \"chipatlas_mESC.csv\"), header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Homer peaks file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to format the peaks to follow the same requirements as the Homer peaks file. The sliding window method also uses this format for convenience.\n",
    "\n",
    "> HOMER peak files should have at minimum 5 columns (separated by TABs, additional columns will be ignored:\n",
    "> - Column1: Unique Peak ID\n",
    "> - Column2: chromosome\n",
    "> - Column3: starting position\n",
    "> - Column4: ending position\n",
    "> - Column5: Strand (+/- or 0/1, where 0=\"+\", 1=\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: I am overriding the workflow to load in the dataset of overlapping ChIP-Atlas and BEELINE edges\n",
    "# See \"map_chip_atlas_to_beeline_ground_truth.ipynb\" for how this was created.\n",
    "chip_bed_cleaned = pd.read_csv(os.path.join(ground_truth_dir, \"chipatlas_beeline_mESC_shared_edges.csv\"), header=0, index_col=False)\n",
    "chip_bed_cleaned[\"peak_id\"] = chip_bed_cleaned.apply(lambda x: format_peak_id(x.chrom, x.start, x.end), axis=1)\n",
    "chip_tf_to_peak = chip_bed_cleaned[[\"source_id\", \"peak_id\"]].rename(columns={\"source_id\":\"gene_id\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the DataFrame to follow the requirements for the Homer peaks file (used for both Homer and sliding window)\n",
    "homer_peaks = chip_bed_cleaned[[\"peak_id\", \"chrom\", \"start\", \"end\"]]\n",
    "homer_peaks = homer_peaks.rename(columns={\"peak_id\":\"PeakID\", \"chrom\":\"chr\"})\n",
    "homer_peaks[\"strand\"] = [\".\"] * len(homer_peaks)\n",
    "homer_peaks[\"start\"] = round(homer_peaks[\"start\"].astype(int),0)\n",
    "homer_peaks[\"end\"] = round(homer_peaks[\"end\"].astype(int),0)\n",
    "homer_peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a huge file - we dont need to test the method using all of them. We will take a sample to run the scoring on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homer_peaks_sample = homer_peaks.sample(frac=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we save the ChIP-seq peaks as `homer_peaks.txt` to the `tmp` directory of the output folder, then they will be used to calculate the sliding window and Homer scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "homer_peak_path = os.path.join(tmp_dir, \"homer_peaks.txt\")\n",
    "homer_peaks_sample.to_csv(homer_peak_path, sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we run `run_sliding_window_on_chipseq_peaks.sh` in the `dev/testing_scripts` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "!sbatch /gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/dev/testing_scripts/run_sliding_window_on_chipseq_peaks.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the sliding window calculation is done, we can read in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sliding_window_df = pd.read_parquet(os.path.join(output_dir, \"sliding_window_tf_to_peak_score.parquet\"), engine=\"pyarrow\")\n",
    "sliding_window_df = sliding_window_df.reset_index(drop=True)\n",
    "sliding_window_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `chip_tf_to_peak` object that we created from the ChIP-Atlas file to check our work. Since we sampled the ChIP-Atlas peaks before running the sliding window calculations, we need to subset `chip_tf_to_peak` to only contain those peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_window_df[\"source_id\"] = sliding_window_df[\"source_id\"].str.upper()\n",
    "chip_tf_to_peak[\"gene_id\"] = chip_tf_to_peak[\"gene_id\"].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_tf_to_peak_sub = chip_tf_to_peak[\n",
    "    (chip_tf_to_peak[\"peak_id\"].isin(sliding_window_df[\"peak_id\"])) &\n",
    "    (chip_tf_to_peak[\"gene_id\"].isin(sliding_window_df[\"source_id\"]))\n",
    "    ]\n",
    "chip_tf_to_peak_sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then combine the TF-peak mapping from ChIP-Atlas with the TF-peak mapping from the sliding window score by merging the two DataFrames on `peak_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df = pd.merge(chip_tf_to_peak_sub, sliding_window_df, on=\"peak_id\", how=\"inner\")\n",
    "merged_df = merged_df.rename(columns={\"gene_id\": \"chip_gene\", \"source_id\": \"sliding_window_gene\"})\n",
    "merged_df = merged_df[[\"chip_gene\", \"sliding_window_gene\", \"peak_id\", \"sliding_window_score\"]]\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(os.path.join(output_dir, \"chipseq_sliding_window_merged.csv\"), header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can extract the correct predictions and the incorrect predictions, and see how the sliding window scores vary between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "\n",
    "merged_ddf = dd.from_pandas(merged_df, npartitions=100)\n",
    "merged_df_sample = merged_ddf.sample(frac=0.05, random_state=42).compute()\n",
    "\n",
    "\n",
    "correct_predictions = merged_df_sample[merged_df_sample[\"chip_gene\"].str.upper() == merged_df_sample[\"sliding_window_gene\"].str.upper()]\n",
    "incorrect_predictions = merged_df_sample[merged_df_sample[\"chip_gene\"].str.upper() != merged_df_sample[\"sliding_window_gene\"].str.upper()]\n",
    "\n",
    "print(f\"Num correct predictions: {len(correct_predictions)}\")\n",
    "print(f\"Num incorrect predictions: {len(incorrect_predictions)}\")\n",
    "\n",
    "print(f\"Num unique correct TFs: {len(correct_predictions.drop_duplicates(subset=['chip_gene', 'sliding_window_gene']))}\")\n",
    "print(f\"Num unique inorrect TFs: {len(incorrect_predictions.drop_duplicates(subset=['chip_gene', 'sliding_window_gene']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since each TF and peak has a potential binding score, there will be a lot more incorrect predictions than correct predictions. We will sample each DataFrame by the one with the minimum number of rows so they are equal in length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_prediction_scores = correct_predictions[\"sliding_window_score\"].sample(\n",
    "    min(len(correct_predictions), len(incorrect_predictions))\n",
    "    ).rename(\"Correct TF Binding Predictions\").reset_index(drop=True)\n",
    "\n",
    "incorrect_prediction_scores = incorrect_predictions[\"sliding_window_score\"].sample(\n",
    "    min(len(correct_predictions), len(incorrect_predictions))\n",
    "    ).rename(\"Incorrect TF Binding Predictions\").reset_index(drop=True)\n",
    "\n",
    "print(f\"Num correct predictions: {len(correct_prediction_scores)}\")\n",
    "print(f\"Num incorrect predictions: {len(incorrect_prediction_scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have extracted the correct and incorrect scores, we will merge them to create a new dataframe containing just the correct and incorrect scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.merge(correct_prediction_scores, incorrect_prediction_scores, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.Figure()\n",
    "a = sns.boxplot(data=pred_df)\n",
    "a.set_ylabel(\"Sliding Window Score\")\n",
    "a.set_title(\"Sliding Window Scores for ChIP-seq TF Binding Predictions\")\n",
    "plt.savefig(\"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/output/chipseq_sliding_window/chipseq_sliding_window_boxplot.png\", dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.hist(\n",
    "    pred_df[\"Correct TF Binding Predictions\"],\n",
    "    bins=150,\n",
    "    alpha=0.7,\n",
    "    color='#4195df',\n",
    "    label=\"Correct TF Binding Predictions\"\n",
    ")\n",
    "plt.hist(\n",
    "    pred_df[\"Incorrect TF Binding Predictions\"],\n",
    "    bins=150,\n",
    "    alpha=0.7,\n",
    "    color='#dc8634',\n",
    "    label=\"Incorrect TF Binding Predictions\"\n",
    ")\n",
    "plt.title(\"Sliding Window Scores for ChIP-seq TF Binding Predictions\", fontsize=16)\n",
    "plt.xlabel(\"Sliding Window Score\", fontsize=14)\n",
    "plt.ylabel(\"Frequency\", fontsize=14)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0., fontsize=14)\n",
    "plt.savefig(\"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/output/chipseq_sliding_window/chipseq_sliding_window_histogram.png\", dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
