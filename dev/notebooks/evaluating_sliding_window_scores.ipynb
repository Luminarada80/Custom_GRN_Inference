{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d00c90c",
   "metadata": {},
   "source": [
    "## Plotting Sliding Window Score AUROC and AUPRC\n",
    "\n",
    "When evaluating the feature score distributions of True / False values after adding MIRA RP scores to our combined DataFrame, we noticed that the `sliding_window_score` feature has a good separation in score distribution between True and False values. The True and False values are from the **RN115 LOGOF ESCAPE** mESC knockout dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47f3752",
   "metadata": {},
   "outputs": [],
   "source": [
    "!hostnamectl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d1cf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "Image(\n",
    "    \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/figures/mm10/DS011/xgboost_feature_score_hist_by_label.png\", \n",
    "    width=800, \n",
    "    height=800\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f21f27f",
   "metadata": {},
   "source": [
    "Now, we are interested in assessing the AUROC and AUPRC for just the sliding window scores.\n",
    "\n",
    "I figured out that the large number of 1 values was due to `clip_and_normalize_log1p_pandas()`. This clips scores below the bottom 5th percentile and above the top 95th percentile and sets them equal to the threshold, then the min-max normalization was moving the distribution to between 0-1. This caused a lot of scores to build up at 0 (the bottom threshold) and 1 (the top threshold).\n",
    "\n",
    "First, we will look at the AUROC and AUPRC as it stands now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99321408",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score\n",
    "output_dir = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/output/DS011_mESC/DS011_mESC_sample1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5045420",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferred_df = pd.read_parquet(os.path.join(output_dir, \"labeled_inferred_grn.parquet\"), engine=\"pyarrow\")\n",
    "sliding_window_score_df = inferred_df[[\"source_id\", \"peak_id\", \"target_id\", \"sliding_window_score\", \"label\"]]\n",
    "sliding_window_score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c606ec77",
   "metadata": {},
   "source": [
    "We first need to balance the number of True and False rows to not skew the accuracy curves as much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092548d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_dataset(df):\n",
    "    true_rows = df[df[\"label\"] == 1]\n",
    "    false_rows = df[df[\"label\"] == 0]\n",
    "\n",
    "    print(\"Before Balancing:\")\n",
    "    print(f\"  - Number of True values: {len(true_rows)}\")\n",
    "    print(f\"  - Number of False values: {len(false_rows)}\")\n",
    "\n",
    "    min_rows = min(len(true_rows), len(false_rows))\n",
    "    print(f\"\\nSubsampling down to {min_rows} rows\")\n",
    "\n",
    "    true_rows_sampled = true_rows.sample(min_rows)\n",
    "    false_rows_sampled = false_rows.sample(min_rows)\n",
    "\n",
    "    balanced_df = pd.concat([true_rows_sampled, false_rows_sampled])\n",
    "\n",
    "    balanced_true_rows = balanced_df[balanced_df[\"label\"] == 1]\n",
    "    balanced_false_rows = balanced_df[balanced_df[\"label\"] == 0]\n",
    "\n",
    "    print(\"\\nAfter Balancing:\")\n",
    "    print(f\"  - Number of True values: {len(balanced_true_rows)}\")\n",
    "    print(f\"  - Number of False values: {len(balanced_false_rows)}\")\n",
    "\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cb3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df = balance_dataset(sliding_window_score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67dbe79",
   "metadata": {},
   "source": [
    "Let's look at the True / False sliding window score histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fda93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_true_false_feature_histogram(\n",
    "    df,\n",
    "    feature_col,\n",
    "    limit_x = True\n",
    "):\n",
    "\n",
    "    fig = plt.figure(figsize=(5, 4))\n",
    "    \n",
    "    true_values = df[df[\"label\"] == 1]\n",
    "    false_values = df[df[\"label\"] == 0]\n",
    "\n",
    "    plt.hist(\n",
    "        false_values[feature_col].dropna(),\n",
    "        bins=50, alpha=0.7,\n",
    "        color=\"#747474\", edgecolor=\"#2D2D2D\",\n",
    "        label=\"False\",\n",
    "    )\n",
    "    plt.hist(\n",
    "        true_values[feature_col].dropna(),\n",
    "        bins=50, alpha=0.7,\n",
    "        color='#1682b1', edgecolor=\"#032b5f\",\n",
    "        label=\"True\",\n",
    "    )\n",
    "\n",
    "    # set titles/labels on the same ax\n",
    "    plt.title(feature_col, fontsize=14)\n",
    "    plt.xlabel(feature_col, fontsize=14)\n",
    "    plt.ylabel(\"Frequency\", fontsize=14)\n",
    "    if limit_x:\n",
    "        plt.xlim(0, 1)\n",
    "\n",
    "    fig.legend(\n",
    "        loc=\"lower center\",\n",
    "        ncol=2,\n",
    "        fontsize=14,\n",
    "        bbox_to_anchor=(0.5, -0.02)\n",
    "    )\n",
    "    fig.tight_layout(rect=[0, 0.05, 1, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36b205",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_false_feature_histogram(balanced_df, \"sliding_window_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64027c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_auroc_auprc(inferred_df):\n",
    "    # Subset the relevant columns\n",
    "    df = inferred_df[[\"sliding_window_score\", \"label\"]].dropna()\n",
    "\n",
    "    # Get true labels and predicted scores\n",
    "    y_true = df[\"label\"]\n",
    "    y_scores = df[\"sliding_window_score\"]\n",
    "\n",
    "    # --- ROC Curve ---\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    # --- PR Curve ---\n",
    "    precision, recall, _ = precision_recall_curve(y_true, y_scores)\n",
    "    avg_precision = average_precision_score(y_true, y_scores)\n",
    "\n",
    "    # --- Plot ---\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    # ROC\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(fpr, tpr, label=f\"AUROC = {roc_auc:.2f}\")\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"ROC Curve\")\n",
    "    plt.legend()\n",
    "\n",
    "    # PR\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(recall, precision, label=f\"AUPRC = {avg_precision:.2f}\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.title(\"Precision-Recall Curve\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "plot_auroc_auprc(balanced_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57083fc9",
   "metadata": {},
   "source": [
    "As expected, there are a large number of incorrect 0 and 1 values from scores above the 95th percentile clipping threshold and below the 5th percentile clipping threshold. Let's see what happens if we filter out sliding window scores with values of 0 or 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_balanced_df = balanced_df[\n",
    "    (balanced_df[\"sliding_window_score\"] > 0) &\n",
    "    (balanced_df[\"sliding_window_score\"] < 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119ee152",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_false_feature_histogram(filtered_balanced_df, \"sliding_window_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163cfe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_auroc_auprc(filtered_balanced_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1002fd4a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6f37f4",
   "metadata": {},
   "source": [
    "### Investigating the bimodal distribution of True scores\n",
    "\n",
    "In the sliding window score distribution, the False scores have a single broad peak around 0.6, while the True scores are bimodal with a lower peak around 0.375 - 0.425 and a higher peak around 0.8 - 0.9. We want to determine what is causing the True values to have multiple peaks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabbc6b5",
   "metadata": {},
   "source": [
    "First, let's look at the number of TFs in the True and False scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9b2a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_true_tfs = sliding_window_score_df[sliding_window_score_df[\"label\"] == 1][\"source_id\"].unique()\n",
    "total_false_tfs = sliding_window_score_df[sliding_window_score_df[\"label\"] == 0][\"source_id\"].unique()\n",
    "\n",
    "print(f\"Total TFs in the True values: {len(total_true_tfs)}\")\n",
    "print(f\"Total TFs in the False values: {len(total_false_tfs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4b2fc5",
   "metadata": {},
   "source": [
    "There are many more TFs in the False values. How many edges does each TF have for the True and False groups?\n",
    "\n",
    "To start answering this question, we can count the number of sliding window scores per TF in each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f374b7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "true_sorted_agg_df = (\n",
    "    sliding_window_score_df[sliding_window_score_df[\"label\"] == 1][[\"source_id\", \"sliding_window_score\"]]\n",
    "    .groupby(\"source_id\")\n",
    "    .count()\n",
    "    .sort_values(by=\"sliding_window_score\", ascending=False)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sliding_window_score\":\"num_scores\"})\n",
    "    )\n",
    "\n",
    "false_sorted_agg_df = (\n",
    "    sliding_window_score_df[sliding_window_score_df[\"label\"] == 0][[\"source_id\", \"sliding_window_score\"]]\n",
    "    .groupby(\"source_id\")\n",
    "    .count()\n",
    "    .sort_values(by=\"sliding_window_score\", ascending=False)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sliding_window_score\":\"num_scores\"})\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2a538a",
   "metadata": {},
   "source": [
    "Now, we can plot the number of scores per TF\n",
    "\n",
    "#### Number of False sliding window scores by TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6998f31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.bar(x=false_sorted_agg_df[\"source_id\"], height=false_sorted_agg_df[\"num_scores\"], color=\"blue\")\n",
    "plt.title(\"Number of False sliding window scores by TF\")\n",
    "plt.ylabel(\"Number of False \\nsliding window scores\", fontsize=12)\n",
    "plt.xticks(rotation=55, fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f292ae3b",
   "metadata": {},
   "source": [
    "#### Number of True sliding window scores by TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd2fe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5,3))\n",
    "plt.bar(x=true_sorted_agg_df[\"source_id\"], height=true_sorted_agg_df[\"num_scores\"], color=\"blue\")\n",
    "plt.title(\"Number of True sliding window scores by TF\")\n",
    "plt.ylabel(\"Number of True \\nsliding window scores\")\n",
    "plt.xticks(rotation=55, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f63626",
   "metadata": {},
   "source": [
    "It looks like there is a relatively small proportion of True values out of the total number of False values. Let's look at the number of scores for TFs with both True and False values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32633a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_values = pd.merge(true_sorted_agg_df, false_sorted_agg_df, on=\"source_id\", how=\"inner\")\n",
    "grouped_values = grouped_values.rename(columns={\n",
    "    \"num_scores_x\": \"Num True Scores\",\n",
    "    \"num_scores_y\": \"Num False Scores\"\n",
    "})\n",
    "grouped_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e550f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_values.plot.bar(x=\"source_id\", stacked=False, figsize=(7,4))\n",
    "plt.title(\"Number of True and False sliding window scores for TFs with True values\")\n",
    "plt.ylabel(\"Number of \\nsliding window scores\", fontsize=12)\n",
    "plt.xticks(rotation=55, fontsize=10)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0706b4c",
   "metadata": {},
   "source": [
    "There are many more scores for the False values. Let's look to see if there are any differences in the True vs False score distributions for each TF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e070ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def plot_tf_score_distributions(df, tf_name_list, score_col, title):\n",
    "    ncols = 4\n",
    "    nrows = math.ceil(len(tf_name_list) / ncols)\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "    fig.set_figwidth(ncols * 3)\n",
    "    fig.set_figheight(nrows * 3)\n",
    "\n",
    "    for i, tf_name in enumerate(tf_name_list):\n",
    "        plot_row = i // ncols\n",
    "        plot_col = i % ncols\n",
    "        \n",
    "        tf_scores = df[df[\"source_id\"] == tf_name][score_col]\n",
    "        \n",
    "        ax[plot_row, plot_col].hist(tf_scores, bins=25)\n",
    "        ax[plot_row, plot_col].set_title(tf_name, fontsize=10)\n",
    "        ax[plot_row, plot_col].tick_params(axis='x', labelsize=9)\n",
    "        ax[plot_row, plot_col].tick_params(axis='y', labelsize=9)\n",
    "        ax[plot_row, plot_col].set_xbound((0, 1))\n",
    "\n",
    "    # Hide the extra plots\n",
    "    n_tfs = len(tf_name_list)\n",
    "    n_figs = ncols * nrows\n",
    "\n",
    "    for i in range(n_tfs, n_figs):\n",
    "        row = i // ncols\n",
    "        col = i % ncols\n",
    "        ax[row, col].axis(\"off\")\n",
    "        \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout(rect=[0.05, 0.05, 1, 1])\n",
    "    \n",
    "    fig.text(0.5, 0.04, 'Sliding Window Score', ha='center', fontsize=12)\n",
    "    fig.text(0.04, 0.5, 'Frequency', va='center', rotation='vertical', fontsize=12)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac9f13d",
   "metadata": {},
   "source": [
    "#### Distribution of True sliding window scores per TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f74af9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df = sliding_window_score_df[sliding_window_score_df[\"label\"] == 1]\n",
    "tfs_with_true_scores = true_df[\"source_id\"].unique()\n",
    "plot_tf_score_distributions(\n",
    "    df=true_df, \n",
    "    tf_name_list=tfs_with_true_scores, \n",
    "    score_col=\"sliding_window_score\",\n",
    "    title=\"True sliding window score distributions by TF\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53e1a92",
   "metadata": {},
   "source": [
    "#### Distribution of False sliding window scores per TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a765996",
   "metadata": {},
   "outputs": [],
   "source": [
    "false_df = sliding_window_score_df[sliding_window_score_df[\"label\"] == 0]\n",
    "plot_tf_score_distributions(\n",
    "    df=false_df, \n",
    "    tf_name_list=tfs_with_true_scores, \n",
    "    score_col=\"sliding_window_score\",\n",
    "    title=\"False sliding window score distributions by TF\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7274111f",
   "metadata": {},
   "source": [
    "The True and False scores appear to have similar distributions for each of the TFs.\n",
    "\n",
    "For the True scores, only the TFs **SOX2**, **SOX9**, and **TCF3** have more than 10 scores. It appears as though these scores are the drivers of the three peaks that we see on the plot. Let's see how the distributions of these scores match up when plotted together. \n",
    "\n",
    ">Note: The number of True and False scores per TF are balanced for the following plot, otherwise the False edges overwhelm the True edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a19d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "\n",
    "def plot_true_false_tf_score_distributions(true_df, false_df, tf_name_list, score_col, title):\n",
    "    ncols = min(len(tf_name_list), 4)\n",
    "    nrows = math.ceil(len(tf_name_list) / ncols)\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "    fig.set_figwidth(ncols * 3)\n",
    "    fig.set_figheight(nrows * 3)\n",
    "    \n",
    "    ax = ax.flatten()\n",
    "\n",
    "    for i, tf_name in enumerate(tf_name_list):\n",
    "        plot_row = i // ncols\n",
    "        plot_col = i % ncols\n",
    "        \n",
    "        true_tf_scores = true_df[true_df[\"source_id\"] == tf_name][score_col]\n",
    "        false_tf_scores = false_df[false_df[\"source_id\"] == tf_name][score_col]\n",
    "        \n",
    "        min_scores = min(len(true_tf_scores), len(false_tf_scores))\n",
    "        true_tf_scores = true_tf_scores.sample(min_scores)\n",
    "        false_tf_scores = false_tf_scores.sample(min_scores)\n",
    "        \n",
    "        ax[i].hist(true_tf_scores, bins=25, alpha=0.7, label=\"True Scores\")\n",
    "        ax[i].hist(false_tf_scores, bins=25, alpha=0.7, label=\"False Scores\")\n",
    "        \n",
    "        ax[i].set_title(tf_name, fontsize=10)\n",
    "        ax[i].tick_params(axis='x', labelsize=9)\n",
    "        ax[i].tick_params(axis='y', labelsize=9)\n",
    "        ax[i].set_xbound((0, 1))\n",
    "\n",
    "    for j in range(len(tf_name_list), len(ax)):\n",
    "        ax[j].axis(\"off\")\n",
    "    \n",
    "    handles, labels = ax[0].get_legend_handles_labels()\n",
    "    fig.legend(\n",
    "        handles,\n",
    "        labels,\n",
    "        loc='upper center',\n",
    "        bbox_to_anchor=(0.5, 1.0),\n",
    "        ncol=2,\n",
    "        fontsize=10,\n",
    "        frameon=False\n",
    "    )\n",
    "        \n",
    "    plt.suptitle(title, y=1.05)\n",
    "    plt.tight_layout(rect=[0.05, 0.05, 1, 0.98])\n",
    "        \n",
    "    fig.text(0.5, 0.04, 'Sliding Window Score', ha='center', fontsize=11)\n",
    "    fig.text(0.04, 0.5, 'Frequency', va='center', rotation='vertical', fontsize=11)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61930941",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_names = [\"SOX2\", \"SOX9\", \"TCF3\"]\n",
    "\n",
    "plot_true_false_tf_score_distributions(\n",
    "    true_df=true_df,\n",
    "    false_df=false_df,\n",
    "    tf_name_list=tf_names,\n",
    "    score_col=\"sliding_window_score\",\n",
    "    title=\"Sliding window score distributions for TFs with True values\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d765725",
   "metadata": {},
   "source": [
    "Let's plot the balanced distributions again, but this time we can color SOX2, SOX9, and TCF3 differently so we can see if they truly are the majority of scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680d3aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tfs_of_interest(\n",
    "    df,\n",
    "    feature_col,\n",
    "    tfs_of_interest,\n",
    "    limit_x = True\n",
    "):\n",
    "\n",
    "    fig = plt.figure(figsize=(7, 5))\n",
    "    \n",
    "    true_values = df[df[\"label\"] == 1]\n",
    "    false_values = df[df[\"label\"] == 0]\n",
    "\n",
    "    plt.hist(\n",
    "        false_values[feature_col].dropna(),\n",
    "        bins=50, alpha=0.3,\n",
    "        color=\"#757575\",\n",
    "        label=\"False Scores\"\n",
    "    )\n",
    "    \n",
    "    y_cmap = plt.get_cmap(\"Dark2\")\n",
    "    \n",
    "    for x, tf in enumerate(tfs_of_interest):\n",
    "        \n",
    "        \n",
    "        true_tfs = true_values[true_values[\"source_id\"] == tf]\n",
    "        \n",
    "        percent_total_true_edges = len(true_tfs[feature_col]) / len(true_values[feature_col])\n",
    "        \n",
    "        nbins=max(10, math.ceil(50*percent_total_true_edges))\n",
    "        \n",
    "        plt.hist(\n",
    "            true_tfs[feature_col].dropna(),\n",
    "            bins=nbins, alpha=0.8,\n",
    "            color=y_cmap.colors[x],\n",
    "            label=tf\n",
    "        )\n",
    "\n",
    "    # set titles/labels on the same ax\n",
    "    plt.title(\"Sliding window score distribution colored by TFs of interest\", fontsize=12)\n",
    "    plt.xlabel(\"Sliding Window Score\", fontsize=12)\n",
    "    plt.ylabel(\"Frequency\", fontsize=12)\n",
    "    if limit_x:\n",
    "        plt.xlim(0, 1)\n",
    "\n",
    "    fig.legend(\n",
    "        loc=\"lower center\",\n",
    "        ncol=1,\n",
    "        fontsize=10,\n",
    "        bbox_to_anchor=(1.10, 0.60)\n",
    "    )\n",
    "    fig.tight_layout(rect=[0, 0, 1, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aa94f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_tfs_of_interest(balanced_df, \"sliding_window_score\", tf_names, limit_x=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_false_feature_histogram(balanced_df, \"sliding_window_score\", limit_x=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f155f00a",
   "metadata": {},
   "source": [
    "Looking at the plot of only the values of the main True TFs, we can see that the three main distributions of True values stems from those TFs having distinct distributions and representing the majority of True edges.\n",
    "\n",
    "Also, if we don't balance the True and False edges, we can see that the True values represent a small majority of the total number of scores. This shows that balancing the scores makes it appear that the True and False scores are more separated than they truly are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb73ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_false_feature_histogram(sliding_window_score_df, \"sliding_window_score\", limit_x=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50558030",
   "metadata": {},
   "source": [
    "## Comparing the knockout ground truth to the ChIP-seq ground truth\n",
    "Now I want to answer the following questions:\n",
    "\n",
    "1. How many TFs and TGs are in the sliding window scores before merging with the knockout ground truth?\n",
    "2. How many TFs and TGs are in the knockout ground truth?\n",
    "3. What does the sliding window analysis look like if I use ChIP-seq data instead of knockout data?\n",
    "    - How many TFs and TGs are in the ChIP-seq ground truth?\n",
    "    - How many True and False TFs match with the ChIP-seq ground truth?\n",
    "    - How many TGs are there for each TF in the ChIP-seq ground truth?\n",
    "  \n",
    "### 1. Number of TFs and TGs are in the sliding window scores before merging with the knockout ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f9cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sliding_window_scores = pd.read_parquet(os.path.join(output_dir, \"no_norm_sliding_window_tf_to_peak_score.parquet\"), engine=\"pyarrow\")\n",
    "raw_sliding_window_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7fa5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_sliding_window_scores.hist(\"sliding_window_score\", bins=50, grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e039c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of TFs in the raw sliding window scores: {len(raw_sliding_window_scores['source_id'].drop_duplicates())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1cc3ee",
   "metadata": {},
   "source": [
    "To find the number of putative TGs, we need to map the peaks to the closest gene TSS. We have the distances from each peak to nearby genes saved in `peaks_near_genes.parquet`, so we will use the data from that file to build our list of peak to TG targets.\n",
    "\n",
    "We start by reading in the file and finding the closest peak to gene target (highest TSS_dist_score value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71793050",
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_near_genes_df = pd.read_parquet(os.path.join(output_dir, \"peaks_near_genes.parquet\"), engine=\"pyarrow\")\n",
    "closest_gene_to_peak_df = peaks_near_genes_df.sort_values(\"TSS_dist_score\", ascending=False).groupby(\"peak_id\").first()\n",
    "closest_gene_to_peak_df = closest_gene_to_peak_df[[\"target_id\"]].reset_index()\n",
    "closest_gene_to_peak_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b2e6e4",
   "metadata": {},
   "source": [
    "Now we can merge the sliding window scores with the closest peak to TG DataFrame to add the closest gene as the target for each row in the sliding window scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d5326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_window_with_targets = pd.merge(raw_sliding_window_scores, closest_gene_to_peak_df, on=[\"peak_id\"], how=\"left\")\n",
    "\n",
    "sliding_window_tf_tg = sliding_window_with_targets[[\"source_id\", \"target_id\", \"sliding_window_score\"]].drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad875031",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db28ba18",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tfs = sliding_window_tf_tg[\"source_id\"].nunique()\n",
    "num_tgs = sliding_window_tf_tg[\"target_id\"].nunique()\n",
    "\n",
    "tf_tg_edges = sliding_window_tf_tg[[\"source_id\", \"target_id\"]].drop_duplicates()\n",
    "\n",
    "print(f\"Number of TFs: {num_tfs:,}\")\n",
    "print(f\"Number of TGs: {num_tgs:,}\")\n",
    "print(f\"Number of TF-TG Edges: {len(tf_tg_edges):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7dd97a",
   "metadata": {},
   "source": [
    "### Finding the number of TFs and TGs in the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1b3696",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b9f5444",
   "metadata": {},
   "source": [
    "#### RN115 LOGOF ESCAPE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319bd1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn115_ko_ground_truth = pd.read_csv(\"/gpfs/Labs/Uzun/DATA/PROJECTS/2024.SC_MO_TRN_DB.MIRA/REPOSITORY/CURRENT/REFERENCE_NETWORKS/RN115_LOGOF_ESCAPE_Mouse_ESC.tsv\", sep=\"\\t\")\n",
    "rn115_ko_ground_truth = rn115_ko_ground_truth[[\"Source\", \"Target\"]].rename(columns={\"Source\":\"source_id\", \"Target\":\"target_id\"})\n",
    "print(f\"Number of TFs: {rn115_ko_ground_truth['source_id'].nunique():,}\")\n",
    "print(f\"Number of TGs: {rn115_ko_ground_truth['target_id'].nunique():,}\")\n",
    "print(f\"Number of Edges: {len(rn115_ko_ground_truth):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn115_ko_ground_truth.groupby(\"source_id\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5759e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_window_tf_tg.groupby(\"source_id\")[\"sliding_window_score\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d87b42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_window_tf_tg.groupby(\"target_id\")[\"sliding_window_score\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588cafb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_edges = pd.merge(sliding_window_tf_tg, rn115_ko_ground_truth, on=[\"source_id\", \"target_id\"], how=\"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13528d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaf3ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_targets[merged_targets[\"target_id\"] == \"Sfpi1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_targets[merged_targets[\"target_id\"] == \"Esx1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93da32",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_targets[\"target_id\"].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c7e74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_edges = merged_targets[merged_targets[\"source_id_x\"] == merged_targets[\"source_id_y\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8747c9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd4a6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_edges.hist(\"sliding_window_score\", bins=150, grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335deee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "same_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1018c8",
   "metadata": {},
   "source": [
    "#### RN111 BEELINE ChIP-seq:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16eacae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grn_inference.utils import read_ground_truth\n",
    "rn111_chipseq_ground_truth = read_ground_truth(\"/gpfs/Labs/Uzun/DATA/PROJECTS/2024.SC_MO_TRN_DB.MIRA/REPOSITORY/CURRENT/REFERENCE_NETWORKS/RN111_ChIPSeq_BEELINE_Mouse_ESC.tsv\")\n",
    "rn111_chipseq_ground_truth['source_id'] = rn111_chipseq_ground_truth['source_id'].str.capitalize()\n",
    "rn111_chipseq_ground_truth['target_id'] = rn111_chipseq_ground_truth['target_id'].str.capitalize()\n",
    "print(f\"Number of TFs: {rn111_chipseq_ground_truth['source_id'].nunique():,}\")\n",
    "print(f\"Number of TGs: {rn111_chipseq_ground_truth['target_id'].nunique():,}\")\n",
    "print(f\"Number of Edges: {len(rn111_chipseq_ground_truth):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e718e7",
   "metadata": {},
   "source": [
    "Let's see how many of the TFs and TGs are shared between the sliding window scores and the ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691d9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sliding Window vs RN115 LOGOF\n",
    "sliding_window_vs_rn115_tfs = tf_tg_edges[tf_tg_edges[\"source_id\"].isin(rn115_ko_ground_truth[\"source_id\"])][\"source_id\"].drop_duplicates()\n",
    "sliding_window_vs_rn115_tgs = tf_tg_edges[tf_tg_edges[\"target_id\"].isin(rn115_ko_ground_truth[\"target_id\"])][\"target_id\"].drop_duplicates()\n",
    "sliding_window_vs_rn115_edges = pd.merge(tf_tg_edges, rn115_ko_ground_truth, on=[\"source_id\", \"target_id\"], how=\"inner\")\n",
    "\n",
    "# Sliding Window vs RN111 ChIP-seq\n",
    "sliding_window_vs_rn111_tfs = tf_tg_edges[tf_tg_edges[\"source_id\"].isin(rn111_chipseq_ground_truth[\"source_id\"])][\"source_id\"].drop_duplicates()\n",
    "sliding_window_vs_rn111_tgs = tf_tg_edges[tf_tg_edges[\"target_id\"].isin(rn111_chipseq_ground_truth[\"target_id\"])][\"target_id\"].drop_duplicates()\n",
    "sliding_window_vs_rn111_edges = pd.merge(tf_tg_edges, rn111_chipseq_ground_truth, on=[\"source_id\", \"target_id\"], how=\"inner\")\n",
    "\n",
    "print(f\"Sliding Window vs RN115 LOGOF Knockout Ground Truth\")\n",
    "print(f\"  - Shared TFs: {len(sliding_window_vs_rn115_tfs):,} / {num_tfs:,}\")\n",
    "print(f\"  - Shared TGs: {len(sliding_window_vs_rn115_tgs):,} / {num_tgs:,}\")\n",
    "print(f\"  - Shared Edges: {len(sliding_window_vs_rn115_edges):,} / {len(tf_tg_edges):,}\")\n",
    "\n",
    "print(f\"\\nSliding Window vs RN111 BEELINE ChIP-seq Ground Truth\")\n",
    "print(f\"  - Shared TFs: {len(sliding_window_vs_rn111_tfs):,} / {num_tfs:,}\")\n",
    "print(f\"  - Shared TGs: {len(sliding_window_vs_rn111_tgs):,} / {num_tgs:,}\")\n",
    "print(f\"  - Shared Edges: {len(sliding_window_vs_rn111_edges):,} / {len(tf_tg_edges):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb6f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_tg_edges[tf_tg_edges.isin(rn115_ko_ground_truth)].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b5e9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn111_chipseq_ground_truth[\"source_id\"].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d82e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_tg_edges[tf_tg_edges[\"source_id\"].isin(rn115_ko_ground_truth[\"source_id\"])][\"source_id\"].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af9c3eb",
   "metadata": {},
   "source": [
    "## Clustering TF-TG Edges\n",
    "\n",
    "To see how the sliding window score varies between TF-TG edges, we can create a clustermap of the average sliding window score for each TF-TG edge. The TGs will be along the x-axis and the TFs along the y-axis, with the mean sliding window score as values. \n",
    "\n",
    "If there are clear score differences between vertical clusters, this indicates that differences in the sliding window scores are driven by TGs. \n",
    "\n",
    "If there are clear score differences between horizontal clusters, this indicates that differences in the sliding window scores are driven by TFs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean sliding window score per TF-TG pair\n",
    "sliding_window_tf_tg_pivot = (\n",
    "    sliding_window_tf_tg\n",
    "    .groupby([\"source_id\", \"target_id\"])\n",
    "    .mean(\"sliding_window_score\")\n",
    "    .rename(columns={\"sliding_window_score\": \"mean_score\"})\n",
    "    .sort_values(\"mean_score\", ascending=False)\n",
    "    ).reset_index().pivot(index=\"source_id\", columns=\"target_id\", values=\"mean_score\")\n",
    "ax = sns.clustermap(sliding_window_tf_tg_pivot, linewidth=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8521806",
   "metadata": {},
   "source": [
    "We can now map the TF and TG clusters back to the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7a7b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster.hierarchy import fcluster\n",
    "\n",
    "# Extract linkage matrices\n",
    "row_linkage = ax.dendrogram_row.linkage\n",
    "col_linkage = ax.dendrogram_col.linkage\n",
    "\n",
    "# Use existing linkage\n",
    "tf_clusters = fcluster(row_linkage, t=5, criterion='maxclust')  # cluster TFs\n",
    "tg_clusters = fcluster(col_linkage, t=5, criterion='maxclust')  # cluster TGs\n",
    "\n",
    "# Create a DataFrame mapping labels to cluster IDs\n",
    "tf_cluster_df = pd.DataFrame({\n",
    "    'source_id': sliding_window_tf_tg_pivot.index,\n",
    "    'tf_cluster': tf_clusters\n",
    "})\n",
    "\n",
    "tg_cluster_df = pd.DataFrame({\n",
    "    'target_id': sliding_window_tf_tg_pivot.columns,\n",
    "    'tg_cluster': tg_clusters\n",
    "})\n",
    "\n",
    "# Merge the TF and TG cluster dataframes with the sliding window TF-TG dataframe\n",
    "sliding_window_tf_tg_clustered = pd.merge(sliding_window_tf_tg, tf_cluster_df, on=\"source_id\", how=\"left\").merge(tg_cluster_df, on=\"target_id\", how='left')\n",
    "sliding_window_tf_tg_clustered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d50aa4d",
   "metadata": {},
   "source": [
    "Now that we have each TF and TG labeled by their cluster, we can see which TF-TG clusters have the highest average sliding window scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d7400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_window_by_cluster = sliding_window_tf_tg_clustered.groupby([\"tf_cluster\", \"tg_cluster\"]).mean(\"sliding_window_score\").reset_index()\n",
    "sliding_window_by_cluster_pivot = sliding_window_by_cluster.pivot(index=\"tf_cluster\", columns=\"tg_cluster\", values=\"sliding_window_score\")\n",
    "sns.heatmap(sliding_window_by_cluster_pivot, linewidth=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac1a7b3",
   "metadata": {},
   "source": [
    "This shows which groups have the highest and lowest sliding window scores. In this case, rows where the TF is in TF cluster 3 and the TG is in TG cluster 3 have the highest sliding window scores. We can cluster the TFs and TGs in this row to see which TFs and TGs have the highest scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe973515",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_tf3_tg3 = sliding_window_tf_tg_clustered[\n",
    "    (sliding_window_tf_tg_clustered[\"tf_cluster\"] == 3) &\n",
    "    (sliding_window_tf_tg_clustered[\"tg_cluster\"] == 3)\n",
    "    ]\n",
    "cluster_tf3_tg3_edges = (\n",
    "    cluster_tf3_tg3[[\"source_id\", \"target_id\", \"sliding_window_score\"]]\n",
    "    .groupby([\"source_id\", \"target_id\"])\n",
    "    .mean(\"sliding_window_score\")\n",
    "    .rename(columns={\"sliding_window_score\":\"mean_score\"})\n",
    "    .reset_index()\n",
    "    )\n",
    "cluster_tf3_tg3_edges_pivot = cluster_tf3_tg3_edges.pivot(index=\"source_id\", columns=\"target_id\", values=\"mean_score\")\n",
    "sns.heatmap(cluster_tf3_tg3_edges_pivot, linewidths=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4972a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ahctf1_sliding_window_scores = sliding_window_with_targets[sliding_window_with_targets[\"source_id\"] == \"Ahctf1\"]\n",
    "ahctf1_sliding_window_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f667443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean sliding window score per TF-TG pair\n",
    "ahctf1_mean_tf_tg_scores = (\n",
    "    ahctf1_sliding_window_scores\n",
    "    .groupby([\"source_id\", \"target_id\"])\n",
    "    .mean(\"sliding_window_score\")\n",
    "    .rename(columns={\"sliding_window_score\": \"mean_score\"})\n",
    "    )\n",
    "\n",
    "# Number of sliding window scores per TF-TG pair\n",
    "ahctf1_count_tf_tg_scores = (\n",
    "    ahctf1_sliding_window_scores\n",
    "    .groupby([\"source_id\", \"target_id\"])\n",
    "    .count()\n",
    "    .drop(columns=\"peak_id\")\n",
    "    .rename(columns={\"sliding_window_score\": \"num_scores\"})\n",
    "    )\n",
    "\n",
    "ahctf1_agg = pd.merge(ahctf1_mean_tf_tg_scores, ahctf1_count_tf_tg_scores, left_index=True, right_index=True, how='inner').reset_index()\n",
    "ahctf1_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff870e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ahctf1_agg_pivot = ahctf1_agg.pivot(index=\"source_id\", columns=\"target_id\", values=\"mean_score\")\n",
    "ahctf1_agg_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c4f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(ahctf1_agg_pivot, cmap=\"hot\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242754f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ahctf1_num_tf_tg_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e5ad66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ahctf1_sliding_window_scores.hist(\"sliding_window_score\", bins=50, grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b744eec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ahctf1_scores_per_tg = (\n",
    "    ahctf1_sliding_window_scores\n",
    "    .groupby([\"source_id\", \"target_id\"])\n",
    "    .count()\n",
    "    .rename(columns={\"sliding_window_score\":\"Number of peaks Per TF-TG pair\"})\n",
    "    )\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "plt.hist(ahctf1_scores_per_tg[\"Number of peaks Per TF-TG pair\"], color=\"blue\", bins=50)\n",
    "plt.title(\"Sliding Window Scores - Number of peaks for each target of Ahctf1\")\n",
    "plt.ylabel(\"Number of unique TGs\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "ahctf1_scores_per_tg.hist(\"Number of peaks Per TF-TG pair\", bins=50, grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f125d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tgs_per_tf_agg = sliding_window_with_targets.groupby([\"source_id\", \"target_id\"]).count()\n",
    "# num_tgs_per_tf_agg = num_tgs_per_tf_agg.drop(\"peak_id\").rename(columns={\"sliding_window_score\":\"num_scores\"})\n",
    "num_tgs_per_tf_agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e76b09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.bar(x=num_tgs_per_tf_agg.index, height=num_tgs_per_tf_agg[\"target_id\"], color=\"blue\")\n",
    "plt.title(\"Sliding Window Scores - Number of TGs per TF\")\n",
    "plt.ylabel(\"Number of unique TGs\", fontsize=12)\n",
    "plt.xticks(rotation=55, fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a16d0aa",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10f8dd2",
   "metadata": {},
   "source": [
    "## Testing the non-normalized sliding window scores using RN111 ChIP-seq as the ground truth\n",
    "\n",
    "We used a knockout dataset as the ground truth for our predictions. Let's test if we see the True / False score distributions separate if we use the RN111 ChIP-seq dataset as the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a77746",
   "metadata": {},
   "source": [
    "### Label sliding window score edges using RN111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b04d6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rn111_chipseq_ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854557d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sliding_window_tf_tg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdd6ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ground_truth_pairs = set(zip(\n",
    "    rn111_chipseq_ground_truth[\"source_id\"].str.upper(),\n",
    "    rn111_chipseq_ground_truth[\"target_id\"].str.upper()\n",
    "))\n",
    "\n",
    "\n",
    "sliding_window_tf_tg[\"source_id\"] = sliding_window_tf_tg[\"source_id\"].str.upper()\n",
    "sliding_window_tf_tg[\"target_id\"] = sliding_window_tf_tg[\"target_id\"].str.upper()\n",
    "\n",
    "def label_partition(df):\n",
    "    df = df.copy()  # <-- avoids SettingWithCopyWarning\n",
    "    tf_tg_tuples = list(zip(df[\"source_id\"], df[\"target_id\"]))\n",
    "    df.loc[:, \"label\"] = [1 if pair in ground_truth_pairs else 0 for pair in tf_tg_tuples]\n",
    "    return df\n",
    "\n",
    "labeled_df = label_partition(sliding_window_tf_tg)\n",
    "\n",
    "labeled_df[\"source_id\"] = labeled_df[\"source_id\"].str.capitalize()\n",
    "labeled_df[\"target_id\"] = labeled_df[\"target_id\"].str.capitalize()\n",
    "labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e90a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_false_feature_histogram(labeled_df, \"sliding_window_score\", limit_x=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b35e34",
   "metadata": {},
   "source": [
    "### Evaluating the True / False sliding window scores by TF against RN111"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb79b89e",
   "metadata": {},
   "source": [
    "Let's look at the number of TFs in the True vs False score distributions in RN111 compared to the RN115 knockout ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeaba22",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_true_tfs = labeled_df[labeled_df[\"label\"] == 1][\"source_id\"].unique()\n",
    "total_false_tfs = labeled_df[labeled_df[\"label\"] == 0][\"source_id\"].unique()\n",
    "\n",
    "print(f\"Total TFs in the True values: {len(total_true_tfs)}\")\n",
    "print(f\"Total TFs in the False values: {len(total_false_tfs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf913d",
   "metadata": {},
   "source": [
    "These are much better numbers - rather than 7 TFs in the True values, we have 75.\n",
    "\n",
    "Let's again look at the number of True and False sliding window scores by TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f5b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_sorted_agg_df = (\n",
    "    labeled_df[labeled_df[\"label\"] == 1][[\"source_id\", \"sliding_window_score\"]]\n",
    "    .groupby(\"source_id\")\n",
    "    .count()\n",
    "    .sort_values(by=\"sliding_window_score\", ascending=False)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sliding_window_score\":\"num_scores\"})\n",
    "    )\n",
    "\n",
    "false_sorted_agg_df = (\n",
    "    labeled_df[labeled_df[\"label\"] == 0][[\"source_id\", \"sliding_window_score\"]]\n",
    "    .groupby(\"source_id\")\n",
    "    .count()\n",
    "    .sort_values(by=\"sliding_window_score\", ascending=False)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sliding_window_score\":\"num_scores\"})\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b786f373",
   "metadata": {},
   "source": [
    "#### Number of False sliding window scores by TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d5176b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.bar(x=false_sorted_agg_df[\"source_id\"], height=false_sorted_agg_df[\"num_scores\"], color=\"blue\")\n",
    "plt.title(\"Number of False sliding window scores by TF\")\n",
    "plt.ylabel(\"Number of False \\nsliding window scores\", fontsize=12)\n",
    "plt.xticks(rotation=55, fontsize=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18abf847",
   "metadata": {},
   "source": [
    "#### Number of True Sliding Window Scores by TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67cda29",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,3))\n",
    "plt.bar(x=true_sorted_agg_df[\"source_id\"], height=true_sorted_agg_df[\"num_scores\"], color=\"blue\")\n",
    "plt.title(\"Number of True sliding window scores by TF\")\n",
    "plt.ylabel(\"Number of True \\nsliding window scores\")\n",
    "plt.xticks(rotation=55, fontsize=6)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfbd191",
   "metadata": {},
   "source": [
    "#### Number of True vs False scores per TF\n",
    "Let's again compare the number of True vs False scores for TFs that have both True and False scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca699cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_values = pd.merge(true_sorted_agg_df, false_sorted_agg_df, on=\"source_id\", how=\"inner\")\n",
    "grouped_values = grouped_values.rename(columns={\n",
    "    \"num_scores_x\": \"Num True Scores\",\n",
    "    \"num_scores_y\": \"Num False Scores\"\n",
    "})\n",
    "grouped_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ebe2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_values.plot.bar(x=\"source_id\", stacked=False, figsize=(12,6))\n",
    "plt.title(\"Number of True and False sliding window scores for TFs with True values\")\n",
    "plt.ylabel(\"Number of \\nsliding window scores\", fontsize=12)\n",
    "plt.xticks(rotation=55, fontsize=8)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eced13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_df_balanced = balance_dataset(labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23140654",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_true_false_feature_histogram(labeled_df_balanced, \"sliding_window_score\", limit_x=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dba37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_true_tfs = labeled_df_balanced[labeled_df_balanced[\"label\"] == 1][\"source_id\"].unique()\n",
    "balanced_false_tfs = labeled_df_balanced[labeled_df_balanced[\"label\"] == 0][\"source_id\"].unique()\n",
    "\n",
    "print(f\"Total TFs in the True values: {len(balanced_true_tfs)}\")\n",
    "print(f\"Total TFs in the False values: {len(balanced_false_tfs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc14cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_true_sorted_agg_df = (\n",
    "    labeled_df_balanced[labeled_df_balanced[\"label\"] == 1][[\"source_id\", \"sliding_window_score\"]]\n",
    "    .groupby(\"source_id\")\n",
    "    .count()\n",
    "    .sort_values(by=\"sliding_window_score\", ascending=False)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sliding_window_score\":\"num_scores\"})\n",
    "    )\n",
    "\n",
    "balanced_false_sorted_agg_df = (\n",
    "    labeled_df_balanced[labeled_df_balanced[\"label\"] == 0][[\"source_id\", \"sliding_window_score\"]]\n",
    "    .groupby(\"source_id\")\n",
    "    .count()\n",
    "    .sort_values(by=\"sliding_window_score\", ascending=False)\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sliding_window_score\":\"num_scores\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd16610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.bar(x=balanced_false_sorted_agg_df[\"source_id\"], height=balanced_false_sorted_agg_df[\"num_scores\"], color=\"blue\")\n",
    "plt.title(\"Number of False sliding window scores by TF\")\n",
    "plt.ylabel(\"Number of False \\nsliding window scores\", fontsize=12)\n",
    "plt.xticks(rotation=55, fontsize=2)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b25bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.bar(x=balanced_true_sorted_agg_df[\"source_id\"], height=balanced_true_sorted_agg_df[\"num_scores\"], color=\"blue\")\n",
    "plt.title(\"Number of True sliding window scores by TF\")\n",
    "plt.ylabel(\"Number of True \\nsliding window scores\", fontsize=12)\n",
    "plt.xticks(rotation=55, fontsize=10)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0e19f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_grouped_values = pd.merge(balanced_true_sorted_agg_df, balanced_false_sorted_agg_df, on=\"source_id\", how=\"inner\")\n",
    "balanced_grouped_values = balanced_grouped_values.rename(columns={\n",
    "    \"num_scores_x\": \"Num True Scores\",\n",
    "    \"num_scores_y\": \"Num False Scores\"\n",
    "})\n",
    "balanced_grouped_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f360b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_values.plot.bar(x=\"source_id\", stacked=False, figsize=(12,6), color=[\"#4195df\",\"#747474\"], width=0.8)\n",
    "plt.title(\"Number of True and False sliding window scores for TFs with True values\")\n",
    "plt.ylabel(\"Number of \\nsliding window scores\", fontsize=12)\n",
    "plt.xticks(rotation=55, fontsize=8)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
