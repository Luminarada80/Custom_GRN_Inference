{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and defining the functions to load in the ground truth, and the melted inferred network score DataFrame and pivot it into a dense matrix. Creates a label column in the inferred network with a label of 1 if the edge is in the ground truth dataset, else 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from dask_ml.model_selection import train_test_split\n",
    "from dask.distributed import Client\n",
    "import xgboost as xgb\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import csv\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(message)s')\n",
    "\n",
    "def read_inferred_network(inferred_network_file: str) -> dd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads a melted sparse inferred network from Parquet and pivots it into a Dask DataFrame\n",
    "    where each row is (source_id, target_id) and columns are score_types (mean-aggregated).\n",
    "    \"\"\"\n",
    "    logging.info(f\"Loading melted sparse network from: {inferred_network_file}\")\n",
    "    melted_ddf = dd.read_parquet(inferred_network_file, engine=\"pyarrow\")\n",
    "\n",
    "    # Standardize IDs\n",
    "    melted_ddf[\"source_id\"] = melted_ddf[\"source_id\"].str.upper()\n",
    "    melted_ddf[\"target_id\"] = melted_ddf[\"target_id\"].str.upper()\n",
    "\n",
    "    # Aggregate scores\n",
    "    grouped_ddf = (\n",
    "        melted_ddf\n",
    "        .groupby([\"source_id\", \"target_id\", \"score_type\"])[\"score_value\"]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Pivot manually by converting to pandas (if dataset is small enough)\n",
    "    def pivot_partition(df):\n",
    "        return df.pivot_table(\n",
    "            index=[\"source_id\", \"target_id\"],\n",
    "            columns=\"score_type\",\n",
    "            values=\"score_value\",\n",
    "            aggfunc=\"mean\"\n",
    "        ).reset_index()\n",
    "\n",
    "    # Apply pivot in a single partition (best if you've already aggregated)\n",
    "    pivot_df = grouped_ddf.compute()  # convert to Pandas here\n",
    "    pivot_df = pivot_partition(pivot_df)\n",
    "    return dd.from_pandas(pivot_df, npartitions=1)\n",
    "\n",
    "def read_ground_truth(ground_truth_file):\n",
    "    logging.info(\"Reading in the ground truth\")\n",
    "    ground_truth = pd.read_csv(ground_truth_file, sep='\\t', quoting=csv.QUOTE_NONE, on_bad_lines='skip', header=0)\n",
    "    ground_truth = ground_truth.rename(columns={\"Source\": \"source_id\", \"Target\": \"target_id\"})\n",
    "    return ground_truth\n",
    "\n",
    "def label_edges_with_ground_truth(inferred_network_dd, ground_truth_df):\n",
    "    logging.info(\"Creating ground truth set\")\n",
    "    ground_truth_pairs = set(zip(\n",
    "        ground_truth_df[\"source_id\"].str.upper(),\n",
    "        ground_truth_df[\"target_id\"].str.upper()\n",
    "    ))\n",
    "\n",
    "    logging.info(\"Adding labels to inferred network\")\n",
    "\n",
    "    def label_partition(df):\n",
    "        df = df.copy()  # <-- avoids SettingWithCopyWarning\n",
    "        tf_tg_tuples = list(zip(df[\"source_id\"], df[\"target_id\"]))\n",
    "        df.loc[:, \"label\"] = [1 if pair in ground_truth_pairs else 0 for pair in tf_tg_tuples]\n",
    "        return df\n",
    "\n",
    "    inferred_network_dd = inferred_network_dd.map_partitions(\n",
    "        label_partition,\n",
    "        meta=inferred_network_dd._meta.assign(label=np.int64(0))\n",
    "    )\n",
    "\n",
    "    return inferred_network_dd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_file: str = \"/gpfs/Labs/Uzun/DATA/PROJECTS/2024.SC_MO_TRN_DB.MIRA/REPOSITORY/CURRENT/REFERENCE_NETWORKS/RN111_ChIPSeq_BEELINE_Mouse_ESC.tsv\"\n",
    "inferred_network_file: str = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/output/mESC/filtered_L2_E7.5_rep1/inferred_grns/inferred_score_df.parquet\"\n",
    "trained_model_dir: str = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/output/mESC/filtered_L2_E7.5_rep1/trained_models\"\n",
    "fig_dir: str = \"/gpfs/Labs/Uzun/SCRIPTS/PROJECTS/2024.SINGLE_CELL_GRN_INFERENCE.MOELLER/figures/mm10/filtered_L2_E7.5_rep1\"\n",
    "model_save_name: str = \"mESC_filtered_L2_E7.5_rep1_xgb_model\"\n",
    "num_cpu: int = int(4)\n",
    "\n",
    "inferred_network_dd = read_inferred_network(inferred_network_file)\n",
    "ground_truth_df = read_ground_truth(ground_truth_file)\n",
    "\n",
    "inferred_network_dd = label_edges_with_ground_truth(inferred_network_dd, ground_truth_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the feature columns to use for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "drop_cols = [\"source_id\", \"peak_id\", \"target_id\", \"label\"]\n",
    "feature_names = [col for col in inferred_network_dd.columns if col not in drop_cols]\n",
    "\n",
    "# Only keep columns needed for modeling\n",
    "logging.info(f\"Keeping {len(feature_names)} feature columns + labels\")\n",
    "model_dd = inferred_network_dd[feature_names + [\"label\"]].persist()\n",
    "\n",
    "logging.info(f\"Splitting {model_dd.shape[0].compute():,} rows into train/test with stratification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
